
# Backend Architecture Plan: Autonomous Trading Engine

This document outlines the architecture for the backend Cloud Functions that will power the autonomous paper trading, analysis, and automation features of Cogmora Labs. The goal is to create a 24/7, server-side system that operates independently of the user's client application.

---

## 1. Core Goal

To transform the paper trading engine from a client-dependent tool into a fully autonomous, persistent service. This architecture is divided into two key parts:

1.  **Scheduled & Event-Driven Logic (Implemented with Cloud Functions)**: Handles periodic tasks like AI analysis and watchlist scraping, and ensures reliable, atomic database operations for events like closing a position. **This part is complete.**
2.  **Real-Time Trigger Execution (Future Vision with Cloud Run)**: Handles instantaneous execution of triggers (like stop-loss) by maintaining a persistent, 24/7 WebSocket connection. This is the next major architectural step.

---

## 2. Implemented Components: Scheduled & Event-Driven Functions

This is the foundational backend system that is currently built and ready for deployment.

-   **Firestore Database**: Serves as the "single source of truth." All state, including user settings (`aiSettings`, `automationConfig`), open positions (`openPositions`), active triggers (`tradeTriggers`), watchlist items (`watchlist`), trade history (`tradeHistory`), and AI agent logs (`aiActionLogs`) is stored here. The frontend UI and the backend functions both read from and write to Firestore.
-   **Cloud Functions for Firebase**: Provides the serverless compute environment where our backend logic executes. We have implemented two primary types of functions:
    1.  **Scheduled Functions (`mainScheduler`)**: Triggered on a recurring schedule (every minute) by Cloud Scheduler. This makes the AI agent and watchlist scraper fully autonomous.
    2.  **Firestore Triggers (`closePositionHandler`)**: Triggered automatically in response to specific data changes in the database, ensuring reliable and secure trade settlement.

### General Data Flow:
1.  **User (Frontend)**: Sets a schedule or configuration (e.g., "Run AI every 15 minutes") in the UI. This intent is written to their user profile in Firestore.
2.  **Cloud Scheduler**: On its defined interval (e.g., every minute), it triggers our main `mainScheduler` Cloud Function.
3.  **`mainScheduler` Cloud Function (Backend)**:
    -   Wakes up and queries the `users` collection in Firestore.
    -   Finds all users whose scheduled tasks are due to run.
    -   **Executes the required logic**: Invokes the Genkit AI flow for AI analysis or the KuCoin scraping logic for the watchlist.
    -   Writes the results (new triggers, updated watchlist) back to Firestore.
    -   Updates the `nextRun` or `lastRun` timestamp in the user's profile for the next cycle.
4.  **User (Frontend)**: The `onSnapshot` listeners in the user's app see the new data in Firestore and the UI updates in real-time, displaying the new triggers or watchlist items generated by the backend, even if the app was closed when the task ran.

---

## 3. Implemented Function Details

### Function 1: Main Scheduler (`mainScheduler`)

This is a single, efficient scheduled function that runs every minute and acts as an orchestrator for all user-specific tasks.

-   **Trigger**: Pub/Sub, via Cloud Scheduler (`every 1 minutes`).
-   **Logic**:
    1.  Get the current timestamp.
    2.  **Query for AI Agent Tasks**: Find all `users` where `aiSettings.scheduleInterval` is set and `aiSettings.nextRun` is in the past.
    3.  **Execute AI Tasks**: For each due user, invoke the `proposeTradeTriggers` Genkit flow and update their database with the results. Update `aiSettings.nextRun`.
    4.  **Query for Watchlist Scraper Tasks**: Find all `users` where `automationConfig.updateMode` is `auto-refresh` and the refresh interval has passed.
    5.  **Execute Scraper Tasks**: For each due user, perform the screener scraping logic and update their `watchlist` subcollection. Update `automationConfig.lastRun`.

### Function 2: Position Closer (`closePositionHandler`)

This function handles the financial calculations for closing a trade, ensuring atomicity and preventing the client from having to perform sensitive logic.

-   **Trigger**: Firestore `onWrite` on the path `/users/{userId}/paperTradingContext/main/openPositions/{positionId}`.
-   **Logic**:
    1.  The function inspects the change. It activates only when a position's `details.status` field is changed to `'closing'`.
    2.  It reads the full position data.
    3.  Calculates the final Profit & Loss (P&L).
    4.  It starts a Firestore transaction to:
        -   Update the user's main `balance`.
        -   Delete the document from the `openPositions` collection.
        -   Update the corresponding `tradeHistory` record.
    5.  The transaction ensures all these database updates succeed or fail together, guaranteeing data integrity.

---

## 4. (Future Vision) Persistent WebSocket Worker for Real-Time Triggers

This component is the **next architectural step** and is **not yet implemented**. It is required for instant, real-time execution of SL/TP and conditional orders.

-   **Architecture**: A dedicated, long-running service (e.g., a Node.js process on **Cloud Run** or a similar container-based service) that maintains a single, persistent WebSocket connection to KuCoin for the `/market/ticker:all` topic.
-   **Logic**:
    1.  Receives a price tick from the WebSocket in real-time.
    2.  Queries all `tradeTriggers` and `openPositions` across all users in Firestore that match the incoming symbol. This would be highly efficient using Firestore's indexing.
    3.  For each matching item, it checks if a price condition is met (e.g., stop-loss, take-profit, or trigger price).
    4.  If a condition is met, it initiates the closing or execution logic by updating the relevant document in Firestore, which in turn would activate our already-built `closePositionHandler` trigger.

This two-part backend (event-driven functions + a persistent worker) is the standard and most robust architecture for this kind of application. The Cloud Functions we have built are the essential first half of this system.
